\chapter{Research Approach}\label{Chap:ResearchApproach}

\lipsum[1-2]



\section{Matrix \& Vector}\label{sec:matrix}
Matrix:
\begin{equation*}
    \mathcal{M}_i 
=
\begin{bmatrix}
A_{1} & A_{2} & \cdots & A_{T}\\
B_{1} & B_{2} & \cdots & B_{T}\\
C_{1} & C_{2} & \cdots & C_{T}\\
\end{bmatrix}_i\in \mathbb{R}^{3\times T}
\end{equation*}

Vector:
\begin{equation*}
 X = 
\begin{bmatrix}
x_{1}\\
x_{2}\\
\vdots\\
x_N
\end{bmatrix} \in \mathbb{R}^{N\times 1}
\end{equation*}

\section{Equations}\label{sec:equation}
Simple equations:
\begin{align}
&\sum\limits_{i=1}^{\tilde{N}}\beta_ig(w_i\cdot x_j+b_i)=\hat y_j, 
\end{align}

Bracket equations: 

$$y_i = \begin{cases}
    1, & \text{True}\\
    0, & \text{False}.
\end{cases}$$



\section{Algorithm}\label{sec:algorithm}: 
\begin{algorithm}
  \caption{Training Extreme Learning Machine (ELM)}
  \label{elm_training_algorithm}
  \begin{algorithmic}[1]
    \renewcommand{\algorithmicrequire}{\textbf{Input:}}
    \renewcommand{\algorithmicensure}{\textbf{Output:}}
    \Require Input matrix $\mathbf{A} \in \mathbb{R}^{N \times d}$, output matrix $Y \in \mathbb{R}^{N \times k}$, activation function $g(\cdot)$
    \Ensure Input weight $\mathbf{W} \in \mathbb{R}^{d \times l}$, hidden bias $\mathbf{b} \in \mathbb{R}^{l \times 1}$, output weight matrix: $\beta \in \mathbb{R}^{l \times k}$

    \State $\mathbf{W}\gets [w_{ij}] \in \mathbb{R}^{d \times l},\  w_{ij} \sim U(-1, 1)$
    
    \State $\mathbf{b}\gets [b_{ij}] \in \mathbb{R}^{l \times 1},\  b_{ij} \sim U(-1, 1)$ 
    
    \State$H \gets g(\mathbf{A} \cdot \mathbf{W} \oplus \mathbf{b}^\top)$
    \State $H^\dagger \gets (H^\top  H)^{-1}  H^\top$
    \State $\hat{\beta} \gets H^\dagger Y$
    \State \textbf{Return} $\mathbf{W}$, $\mathbf{b}$, $\hat{\beta}$
  \end{algorithmic}
\end{algorithm}

 
