\chapter*{LIST OF SYMBOLS}
\addcontentsline{toc}{chapter}{List of Symbols}
\begin{flushleft}
\begin{tabular}{ll}

$I$ & Identity matrix\\

$N$ & Number of samples in a dataset \\

$\lambda$ & Number of internal units of the ESN layer \\

$C$ & Number of channels of signal data \\

$M$ & Number of class of data \\

$T$ & Period length of signal data\\

$\mathcal{S}$ & A signal matrix of size $T\times C$\\

$s_t$ & A signal point at time $t$\\

$X$ & A tensor dataset of signal data of size $N\times T\times C$\\

$Y$ & A matrix of label of size $N \times 2$\\

$h_t$ & A hidden state at time $t$\\

$H$ & A Hidden matrix\\

$\mathcal{H}$ & List of hidden matrix $[H_1;H_2;\cdots;H_N]$ \\

$R$ & Ridge Embedding of $H$\\

$\mathcal{R}$ & List of Ridge Embedding $[R_1;R_2;\cdots;R_N]$\\

$n$ & The time steps for embedding\\

$W_{input}$ & An input matrix of the ESN of size $\lambda\times C$\\

$W_{h}$ & An internal units matrix of the ESN of size $\lambda\times \lambda$\\

$W_{output}$ & An output matrix of the Multi-ESELM of size $2 \times\lambda$\\

$g(\cdot)$ & A Non-linear function or hidden neuron activation function\\

$\tanh(\cdot)$ & A tangent function\\

$flatten(\cdot)$ & A flatten function is a function to flat a vector or a matrix to a row vector.\\

$l$ & Number of hidden units of ELM\\

$\mathbf{A}$ & Input data of ELM\\ 

$\mathbf{G}$ & A hidden layermatrix of ELM\\

$\mathcal{B}$ & An outpit weight of ELM\\

$A$ & A coefficient vector of solution of a least square problem\\

$B$ & A bias vector of solution of the least square \\

\end{tabular}
\end{flushleft}